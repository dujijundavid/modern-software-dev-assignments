# CLAUDE.md

This document contains configuration and guidance for Claude Code agents working on this CS146S Modern Software Developer course assignments repository.

---

## üß† AI Engineering Mindset (The "Mihail Eric" Framework)

When working on this repository, adopt the **Agentic Development** mindset:

### Core Principle: Build Systems, Not Just Code

You are not a "coder" ‚Äî you are an **AI workflow architect**. Every task should be evaluated through:

```
ü§î The Three Questions:
1Ô∏è‚É£ What's the bottleneck?     Âì™ÈáåÊòØÈáçÂ§çÊÄß„ÄÅ‰Ωé‰ª∑ÂÄºÁöÑÂ∑•‰ΩúÔºü
2Ô∏è‚É£ What's the leverage point? Â¶Ç‰ΩïËÆ©Ëøô‰∏™Ëá™Âä®ÂåñÂèØÂ§çÁî®„ÄÅÂèØÁªÑÂêàÔºü
3Ô∏è‚É£ How to compound value?     Ëøô‰∏™Ëá™Âä®ÂåñÂ¶Ç‰Ωï‰∏éÂÖ∂‰ªñËá™Âä®Âåñ‰∫ßÁîü 1+1>3 ÁöÑÊïàÊûúÔºü
```

### The Automation Hierarchy

```
Level 1: One-off Script    ‚Üí Ëß£ÂÜ≥‰∏ÄÊ¨°ÈóÆÈ¢ò
Level 2: Reusable Function ‚Üí Ëß£ÂÜ≥‰∏ÄÁ±ªÈóÆÈ¢ò
Level 3: Composable System ‚Üí ÂèØ‰ª•‰∏éÂÖ∂‰ªñËá™Âä®ÂåñÁªÑÂêà
Level 4: Self-Improving    ‚Üí ËÉΩÂ§üÂèëÁé∞Âíå‰ºòÂåñËá™Â∑±ÁöÑÁì∂È¢à
```

**Goal**: Always aim for Level 3+.

### Before Writing Code, Ask:

- ‚úÖ **Is this task repeatable?** If yes, design for automation
- ‚úÖ **Can this be parameterized?** Make it configurable, not hardcoded
- ‚úÖ **What's the input/output contract?** Define clear interfaces
- ‚úÖ **How will this fail?** Add error handling and rollback
- ‚úÖ **Can this run concurrently?** Design for parallel execution

### For Week 5 (Agentic Development with Warp):

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Week 5 ÊÄùËÄÉÊ°ÜÊû∂                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1Ô∏è‚É£ ËßÇÂØüÔºàObserveÔºâ
   - ÂΩìÂâçÂ∑•‰ΩúÊµÅ‰∏≠ÊúâÂì™‰∫õÈáçÂ§çÊÄßÊ≠•È™§Ôºü
   - Âì™‰∫õ‰ªªÂä°ÈúÄË¶Å‰∏ä‰∏ãÊñáÂàáÊç¢Ôºü
   - Âì™‰∫õÈîôËØØ‰Ω†ÁäØ‰∫Ü‰∏çÊ≠¢‰∏ÄÊ¨°Ôºü

2Ô∏è‚É£ ÂÆö‰πâÔºàDefineÔºâ
   - Â¶ÇÊûúÂè™ËÉΩËá™Âä®Âåñ‰∏Ä‰ª∂‰∫ãÔºåÊòØ‰ªÄ‰πàÔºü
   - Ëøô‰∏™Ëá™Âä®ÂåñÁöÑËæìÂÖ•/ËæìÂá∫ÊòØ‰ªÄ‰πàÔºü
   - Â¶Ç‰ΩïËÆ©ÂÆÉÂèØÂ§çÁî®Ôºü

3Ô∏è‚É£ ÊûÑÂª∫
   - ËÆæËÆ° Warp saved prompt/rule
   - ÊµãËØïÂÆÉÊòØÂê¶ÂèØÂ§çÁé∞
   - ËÆ∞ÂΩïËæπÁïåÊÉÖÂÜµ

4Ô∏è‚É£ ÁªÑÂêàÔºàComposeÔºâ
   - Âì™‰∫õËá™Âä®ÂåñÂèØ‰ª•ÈìæÂºèË∞ÉÁî®Ôºü
   - Â§ö‰ª£ÁêÜÂ¶Ç‰ΩïÂπ∂ÂèëËÄå‰∏çÂÜ≤Á™ÅÔºü
   - Â§±Ë¥•Êó∂Â¶Ç‰ΩïÂõûÊªöÔºü

5Ô∏è‚É£ ÂèçÊÄùÔºàReflectÔºâ
   - Ëøô‰∏™Ëá™Âä®ÂåñÁúüÁöÑËäÇÁúÅÊó∂Èó¥‰∫ÜÂêóÔºü
   - ÂÆÉÁöÑÂèØÁª¥Êä§ÊÄßÂ¶Ç‰ΩïÔºü
   - ‰∏ãÊ¨°Â¶Ç‰ΩïÊîπËøõÔºü
```

### Multi-Agent Coordination Strategy

When working with multiple agents (Warp tabs, subagents):

```yaml
Coordination Pattern:
  - Define clear ownership (which agent owns what)
  - Use git branches/worktrees for isolation
  - Share contracts (schemas, interfaces) not implementation
  - Design failure recovery (what if Agent A fails?)
  - Maximize parallelism, minimize coordination overhead
```

---

## AI Team Configuration (autogenerated by team-configurator, 2025-12-28)

**Important: YOU MUST USE subagents when available for the task.**

### Detected Tech Stack

| Component | Technology |
|-----------|------------|
| Backend Framework | FastAPI (Python 3.10+) |
| Database | SQLite (with SQLAlchemy 2.0+) |
| Frontend | Vanilla JavaScript + HTML/CSS |
| LLM Integration | Ollama (llama3.1:8b), OpenAI SDK |
| Testing | pytest + httpx (TestClient) |
| Code Quality | Black (formatter), Ruff (linter), pre-commit |
| Package Management | Poetry 2.2.1 |
| Environment | Conda (Python 3.12.7) |

### AI Team Assignments

| Task | Agent | Notes |
|------|-------|-------|
| **All code changes** | `code-reviewer` | MUST run after every feature/bug-fix before committing |
| **Performance issues** | `performance-optimizer` | For slowness, high cloud costs, scaling concerns |
| **Codebase exploration** | `code-archaeologist` | Use when analyzing unfamiliar code or legacy modules |
| **Documentation updates** | `documentation-specialist` | For README, API docs, guides |
| **FastAPI development** | `fastapi-expert` | Primary for all API endpoints, routers, middleware |
| **Python backend** | `python-expert` | For Python-specific tasks outside FastAPI scope |
| **Testing & pytest** | `python-testing-expert` | Test structure, fixtures, coverage improvements |
| **Security analysis** | `python-security-expert` | For SQL injection, XSS, auth vulnerabilities |
| **API design** | `api-architect` | For new API contracts, REST design, versioning |
| **Frontend (JS/HTML/CSS)** | `frontend-developer` | For vanilla JS, HTML, CSS updates |
| **LLM/AI integration** | `ml-data-expert` | For Ollama/OpenAI integration, prompt engineering |
| **DevOps/CI-CD** | `python-devops-cicd-expert` | For Poetry, pre-commit, GitHub Actions |

### Weekly Assignment Workflow (Enhanced with AI Engineering Mindset)

For each week's assignments, follow this pattern:

1. **Observe**: Use `code-archaeologist` to understand the current state
   - What patterns exist? What's repeated?
   - Where are the friction points?

2. **Define**: Before implementing, ask:
   - Can this be automated for future weeks?
   - What's the input/output contract?
   - How will this be tested and validated?

3. **Plan**: Use `fastapi-expert` or `python-expert` to design implementation
   - Design for composability
   - Define clear interfaces

4. **Implement**: Use appropriate specialist (e.g., `fastapi-expert` for API work)
   - Follow existing patterns
   - Make changes minimal and focused

5. **Test**: Use `python-testing-expert` for test improvements
   - Test edge cases, not just happy paths
   - Ensure tests are fast and reliable

6. **Review**: ALWAYS use `code-reviewer` before committing
   - Security vulnerabilities?
   - Performance concerns?
   - Code quality issues?

7. **Reflect**: After completion
   - What was learned?
   - What can be automated?
   - What would make this faster next time?

### Custom Slash Commands Available

| Command | Purpose |
|---------|---------|
| `/week` | Get help with a specific weekly assignment |
| `/explore-week` | Deep dive into a week's current state |
| `/test-week` | Run and analyze tests for a week |
| `/llm-extract` | Help with LLM extraction (Week 2) |
| `/mcp-server` | Help with MCP server development (Week 3) |
| `/refactor` | Systematic code cleanup and refactoring |

### Key Project Patterns

- **Database**: SQLite with custom exceptions (`DatabaseError`, `NotFoundError`)
- **API Structure**: FastAPI routers in `app/routers/`, services in `app/services/`
- **Testing**: pytest with test paths configured for all weeks (1-8)
- **Error Handling**: Custom exception handlers in FastAPI apps
- **LLM Integration**: Ollama for local inference with structured JSON outputs

### Agent Selection Priority

1. **FastAPI tasks** ‚Üí `fastapi-expert` (framework-specific)
2. **Python general** ‚Üí `python-expert`
3. **Testing** ‚Üí `python-testing-expert`
4. **Security** ‚Üí `python-security-expert`
5. **Performance** ‚Üí `performance-optimizer`
6. **Always** ‚Üí `code-reviewer` before commits

### Example Usage

```
# Implementing a new endpoint
Use @fastapi-expert to add a new notes endpoint with proper error handling

# Improving test coverage
Use @python-testing-expert to increase test coverage for week2 action_items

# Security review
Use @code-reviewer to review the authentication implementation

# Performance optimization
Use @performance-optimizer to analyze slow database queries
```

---

## üéØ Week 5 Specific Guidance: Agentic Development with Warp

### Recommended Automation Priority (Based on Leverage)

```yaml
Tier 1 (Foundation - Do First):
  - Environment Setup & Health Check
  - Test Runner with Coverage
  - Format + Lint Pipeline

Tier 2 (High Leverage):
  - API Response Standardization (Task 7)
  - Pagination Pattern (Task 8)
  - Error Handling Wrapper

Tier 3 (Feature-Level):
  - Notes Search (Task 2)
  - Bulk Operations (Task 4)
  - Extraction Logic (Task 6)

Tier 4 (Complex/Advanced):
  - Frontend Migration to React (Task 1)
  - Tags Feature (Task 5)
  - Vercel Deployment (Task 11)
```

### Example Warp Saved Prompts

**Prompt 1: "Add Pagination to Endpoint"**
```
Context: FastAPI backend with SQLAlchemy
Task: Add pagination support to {endpoint}
Input: Endpoint path, model name
Output: Updated endpoint with page/page_size params, returns {items, total}
Pattern:
  1. Add page/page_size query params (default: page=1, page_size=10)
  2. Apply .offset() and .limit() to query
  3. Run COUNT(*) query for total
  4. Return {"items": [...], "total": N, "page": 1, "page_size": 10}
  5. Add tests for edge cases (empty, last page, negative page)
```

**Prompt 2: "Standardize API Response"**
```
Context: FastAPI endpoints need consistent error handling
Task: Wrap {endpoint} with standard response envelope
Pattern:
  Success: {"ok": true, "data": {...}}
  Error: {"ok": false, "error": {"code": "NOT_FOUND", "message": "..."}}
Steps:
  1. Create response schemas in schemas.py
  2. Wrap return values in response envelope
  3. Add exception handlers for common errors
  4. Update tests to assert envelope shape
```

**Prompt 3: "Multi-Agent Task Runner"**
```
Context: Week 5 multi-agent workflow
Task: Coordinate 3 agents working on different tasks
Agents:
  - Agent A: Backend API (works in backend/)
  - Agent B: Frontend UI (works in frontend/)
  - Agent C: Tests (works in backend/tests/)
Coordination:
  1. Create git worktree for each agent
  2. Define shared contract (e.g., OpenAPI spec)
  3. Run agents in parallel
  4. Agent C validates A and B's work
  5. If C fails, rollback A and B
  6. If all pass, merge worktrees
```

### Multi-Agent Anti-Patterns to Avoid

‚ùå **Don't**: Let agents edit the same files simultaneously
‚úÖ **Do**: Use git worktrees or clear ownership boundaries

‚ùå **Don't**: Run agents without validation checkpoints
‚úÖ **Do**: Have agent C (tests) validate before merging

‚ùå **Don't**: Mix concerns (e.g., agent edits both backend and frontend)
‚úÖ **Do**: One concern per agent, clear interfaces

‚ùå **Don't**: Hard-code values (e.g., port 8000, localhost)
‚úÖ **Do**: Parameterize everything (use env vars, config)

### Automation Evaluation Rubric

Before submitting your Week 5 work, score each automation:

```
üìä Automation Scorecard

Reusability (1-5):
  1 = One-off, hardcoded
  3 = Can be used for similar tasks with minor tweaks
  5 = Fully parameterized, works for any similar task

Composability (1-5):
  1 = Standalone, can't combine with others
  3 = Can be chained manually
  5 = Designed to compose, has clear input/output contracts

Autonomy (1-5):
  1 = Requires constant human intervention
  3 = Runs autonomously with supervision
  5 = Fully autonomous, handles edge cases and self-recovers

Robustness (1-5):
  1 = Fails silently or catastrophically
  3 = Fails gracefully with errors
  5 = Handles errors, rolls back, reports issues

Total Score: ___ / 20
Goal: 12+ for each automation
```

### Quick Start: First Automation to Build

If you're stuck, start with this:

**"Environment Health Check" Automation**
```yaml
Name: env-health-check
Trigger: When starting work or after git pull
Steps:
  1. Check Python version >= 3.10
  2. Verify poetry.lock is up to date
  3. Run pytest --collect-only (ensure tests discoverable)
  4. Check database exists, run seed if needed
  5. Start server, wait for /docs to respond
  6. Report status with actionable next steps
Output: Terminal summary with ‚úÖ/‚ùå for each check
Why: This saves 10-15 minutes every time you switch contexts
```

### Writeup Template for Week 5

For your `week5/writeup.md`, use this structure:

```markdown
## Automation 1: [Name]

### Goal
What problem does this solve?

### Design
- Input: ...
- Output: ...
- Steps: ...

### Warp Implementation
- Saved prompt / rule / MCP server: (paste or link)
- How to use: ...

### Before vs After
- Before: [describe manual workflow]
- After: [describe automated workflow]
- Time saved: ...

### Autonomy Level
- Code permissions: (read/write/execute)
- Supervision: (full / partial / none)
- Why: ...

### Multi-Agent Notes (if applicable)
- Agent roles: ...
- Coordination: ...
- Concurrency wins: ...
- Failures encountered: ...

### How I Used It
[Pain point it resolved or accelerated]
```

---

## üí° Pro Tips from Prof. Eric

1. **Start Small, Then Scale**
   - First automation: something you'll use daily
   - Second automation: something that helps others
   - Third automation: something that combines 1 + 2

2. **Document as You Build**
   - Don't "document later" ‚Äî you won't
   - Write the docs before writing the automation
   - Update docs when you find edge cases

3. **Test Your Automations**
   - Run them 5 times in a row
   - If they fail once, they're not reliable enough
   - Add error handling until they pass 5/5 times

4. **Share and Iterate**
   - Show your automations to classmates
   - Ask: "Would you use this? Why or why not?"
   - Improve based on feedback

5. **Think in Workflows, Not Tasks**
   - A task is "add pagination to notes endpoint"
   - A workflow is "from idea to deployed feature with tests"
   - Automate workflows, not just tasks

---

## üéì Final Thought

"The best AI engineers aren't the ones who write the most code. They're the ones who build systems that write, test, and deploy code automatically while they sleep."

‚Äî Mihail Eric (paraphrased)

Your goal in Week 5: **Build one such system.**

---



