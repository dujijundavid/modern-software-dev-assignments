"""
Chain of Thought (CoT) Prompting å®éªŒè„šæœ¬

æœ¬è„šæœ¬è®¾è®¡äº†ä¸€ä¸ªç§‘å­¦çš„å¯¹æ¯”å®éªŒæ¡†æ¶ï¼Œå¸®åŠ©ä½ ç†è§£CoTçš„æ•ˆæœï¼š
1. å¯¹æ¯”5ç§ä¸åŒçš„promptingç­–ç•¥
2. æµ‹è¯•å¤šä¸ªé—®é¢˜éªŒè¯æ³›åŒ–èƒ½åŠ›
3. è¯„ä¼°å‡†ç¡®ç‡å’Œæ¨ç†è´¨é‡
4. å¯è§†åŒ–å±•ç¤ºå®éªŒç»“æœ

å­¦ä¹ ç›®æ ‡ï¼š
- ç†è§£CoTä¸ºä»€ä¹ˆæœ‰æ•ˆ
- åŒºåˆ†"å¼•å¯¼æ€è€ƒ"å’Œ"ç­”æ¡ˆæ³„éœ²"
- æŒæ¡è®¾è®¡æœ‰æ•ˆCoT promptçš„åŸåˆ™
"""

import os
import re
from dataclasses import dataclass
from typing import Callable
from dotenv import load_dotenv
from ollama import chat

load_dotenv()

NUM_RUNS_TIMES = 3  # æ¯ä¸ªç­–ç•¥è¿è¡Œæ¬¡æ•°

# =============================================================================
# å®éªŒé—®é¢˜å®šä¹‰
# =============================================================================

@dataclass
class Problem:
    """å®šä¹‰ä¸€ä¸ªæµ‹è¯•é—®é¢˜"""
    name: str
    question: str
    expected_answer: str
    difficulty: str  # easy, medium, hard


# ä¸»é—®é¢˜ï¼šä½œä¸šè¦æ±‚çš„é—®é¢˜
MAIN_PROBLEM = Problem(
    name="Modular Exponentiation (Main)",
    question="What is 3^12345 (mod 100)?",
    expected_answer="43",
    difficulty="hard"
)

# é¢å¤–æµ‹è¯•é—®é¢˜ï¼ˆéªŒè¯æ³›åŒ–èƒ½åŠ›ï¼‰
EXTRA_PROBLEMS = [
    Problem(
        name="Simple Modular",
        question="What is 2^10 (mod 7)?",
        expected_answer="2",
        difficulty="easy"
    ),
    Problem(
        name="Medium Modular",
        question="What is 7^2023 (mod 13)?",
        expected_answer="11",
        difficulty="medium"
    ),
]

# =============================================================================
# 5ç§å®éªŒç­–ç•¥
# =============================================================================

# ç­–ç•¥A: Baseline - æ— ä»»ä½•CoTå¼•å¯¼
STRATEGY_A_BASELINE = """You are a mathematician. Answer math questions accurately.
Give your final answer on the last line as "Answer: <number>"."""

# ç­–ç•¥B: Zero-shot CoT - åªç”¨é­”æ³•å’’è¯­
STRATEGY_B_ZERO_SHOT_COT = """You are a mathematician.
When solving problems, think through each step carefully.
Let's think step by step.
Give your final answer on the last line as "Answer: <number>"."""

# ç­–ç•¥C: Structured CoT - ç»™å‡ºæ¨ç†æ¡†æ¶ä½†ä¸ç»™å…·ä½“è®¡ç®—
STRATEGY_C_STRUCTURED_COT = """You are a mathematician skilled in modular arithmetic.

When solving modular exponentiation problems (a^n mod m):
1. ANALYZE: Identify the base (a), exponent (n), and modulus (m)
2. SIMPLIFY: Look for patterns or theorems to reduce the problem
3. CALCULATE: Perform the computation step by step
4. VERIFY: Check your answer makes sense

Show each step of your reasoning.
Give your final answer on the last line as "Answer: <number>"."""

# ç­–ç•¥D: Domain-Specific CoT - æä¾›é¢†åŸŸçŸ¥è¯†ä½†ä¸ç›´æ¥åº”ç”¨
STRATEGY_D_DOMAIN_COT = """You are a mathematician skilled in modular arithmetic.

Useful theorems for modular exponentiation:
- Euler's Theorem: a^Ï†(n) â‰¡ 1 (mod n) when gcd(a,n)=1
- Euler's totient: Ï†(100) = 40, Ï†(13) = 12, Ï†(7) = 6
- For prime p: Ï†(p) = p-1 (Fermat's Little Theorem)

Approach:
1. Check if Euler's theorem or Fermat's Little Theorem applies
2. Find the cycle length using the totient function
3. Reduce the large exponent using: a^n â‰¡ a^(n mod Ï†(m)) (mod m)
4. Calculate the final result

Show your work step by step.
Give your final answer on the last line as "Answer: <number>"."""

# ç­–ç•¥E: Few-shot CoT - ç”¨ä¸åŒé—®é¢˜çš„ç¤ºä¾‹å±•ç¤ºæ¨ç†è¿‡ç¨‹
STRATEGY_E_FEW_SHOT_COT = """You are a mathematician. Here are examples of solving modular exponentiation:

Example 1: What is 5^100 mod 13?
Thinking:
- 13 is prime, so by Fermat's Little Theorem: 5^12 â‰¡ 1 (mod 13)
- 100 = 12 Ã— 8 + 4
- So 5^100 â‰¡ 5^4 (mod 13)
- 5^4 = 625 = 48 Ã— 13 + 1 = 625 - 624 = 1
Answer: 1

Example 2: What is 3^20 mod 7?
Thinking:
- 7 is prime, so by Fermat's Little Theorem: 3^6 â‰¡ 1 (mod 7)
- 20 = 6 Ã— 3 + 2
- So 3^20 â‰¡ 3^2 = 9 â‰¡ 2 (mod 7)
Answer: 2

Now solve the given problem using similar step-by-step reasoning.
Give your final answer on the last line as "Answer: <number>"."""

# æ‰€æœ‰ç­–ç•¥æ±‡æ€»
STRATEGIES = {
    "A_Baseline": STRATEGY_A_BASELINE,
    "B_ZeroShot_CoT": STRATEGY_B_ZERO_SHOT_COT,
    "C_Structured_CoT": STRATEGY_C_STRUCTURED_COT,
    "D_Domain_CoT": STRATEGY_D_DOMAIN_COT,
    "E_FewShot_CoT": STRATEGY_E_FEW_SHOT_COT,
}

# =============================================================================
# ç”¨äºä½œä¸šæäº¤çš„æœ€ç»ˆç­–ç•¥ (TODO: æ ¹æ®å®éªŒç»“æœé€‰æ‹©æœ€ä½³ç­–ç•¥)
# =============================================================================

# TODO: è¿è¡Œå®Œå®éªŒåï¼Œé€‰æ‹©è¡¨ç°æœ€å¥½çš„ç­–ç•¥å¡«å…¥è¿™é‡Œ
YOUR_SYSTEM_PROMPT = STRATEGY_D_DOMAIN_COT

USER_PROMPT = """Solve this problem step by step, then give the final answer on the last line as "Answer: <number>".

What is 3^12345 (mod 100)?

Remember to:
1. Use modular arithmetic properties
2. Show intermediate calculations
3. End with "Answer: <number>" on the last line"""

EXPECTED_OUTPUT = "Answer: 43"

# =============================================================================
# è¾…åŠ©å‡½æ•°
# =============================================================================

def extract_final_answer(text: str) -> str:
    """Extract the final 'Answer: ...' line from a verbose reasoning trace."""
    matches = re.findall(r"(?mi)^\\s*answer\\s*:\\s*(.+)\\s*$", text)
    if matches:
        value = matches[-1].strip()
        num_match = re.search(r"-?\\d+(?:\\.\\d+)?", value.replace(",", ""))
        if num_match:
            return f"Answer: {num_match.group(0)}"
        return f"Answer: {value}"
    return text.strip()


def run_single_test(system_prompt: str, problem: Problem, verbose: bool = False) -> tuple[bool, str, str]:
    """è¿è¡Œå•æ¬¡æµ‹è¯•ï¼Œè¿”å›(æ˜¯å¦æˆåŠŸ, æå–çš„ç­”æ¡ˆ, å®Œæ•´è¾“å‡º)"""
    user_prompt = f"""Solve this problem step by step, then give the final answer on the last line as "Answer: <number>".

{problem.question}"""
    
    response = chat(
        model="mistral-nemo:12b",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        options={"temperature": 0.3},
    )
    
    output_text = response.message.content
    final_answer = extract_final_answer(output_text)
    expected = f"Answer: {problem.expected_answer}"
    success = final_answer.strip() == expected.strip()
    
    if verbose:
        print(f"\\n{'â”€'*60}")
        print(f"Full Output:\\n{output_text}")
        print(f"{'â”€'*60}")
        print(f"Extracted: {final_answer} | Expected: {expected} | {'âœ“' if success else 'âœ—'}")
    
    return success, final_answer, output_text


# =============================================================================
# å®éªŒè¿è¡Œå‡½æ•°
# =============================================================================

def run_experiment(strategies: dict, problems: list[Problem], num_runs: int = 3, verbose: bool = False):
    """è¿è¡Œå®Œæ•´çš„å¯¹æ¯”å®éªŒ"""
    results = {}
    
    print("=" * 70)
    print("Chain of Thought å¯¹æ¯”å®éªŒ")
    print("=" * 70)
    
    for strategy_name, system_prompt in strategies.items():
        print(f"\\n{'='*70}")
        print(f"ç­–ç•¥: {strategy_name}")
        print(f"{'='*70}")
        
        strategy_results = {}
        
        for problem in problems:
            print(f"\\n  é—®é¢˜: {problem.name} ({problem.difficulty})")
            print(f"  {problem.question}")
            
            successes = 0
            answers = []
            
            for run_idx in range(num_runs):
                success, answer, output = run_single_test(system_prompt, problem, verbose=verbose)
                successes += 1 if success else 0
                answers.append(answer)
                status = "âœ“" if success else "âœ—"
                print(f"    Run {run_idx + 1}: {answer} {status}")
            
            accuracy = successes / num_runs * 100
            strategy_results[problem.name] = {
                "accuracy": accuracy,
                "answers": answers,
                "expected": problem.expected_answer
            }
            print(f"  å‡†ç¡®ç‡: {successes}/{num_runs} ({accuracy:.1f}%)")
        
        results[strategy_name] = strategy_results
    
    return results


def print_summary(results: dict):
    """æ‰“å°å®éªŒç»“æœæ±‡æ€»è¡¨"""
    print("\\n" + "=" * 70)
    print("å®éªŒç»“æœæ±‡æ€»")
    print("=" * 70)
    
    # æ”¶é›†æ‰€æœ‰é—®é¢˜åç§°
    problem_names = []
    for strategy_results in results.values():
        for pname in strategy_results.keys():
            if pname not in problem_names:
                problem_names.append(pname)
    
    # æ‰“å°è¡¨å¤´
    header = f"{'ç­–ç•¥':<20}"
    for pname in problem_names:
        header += f" | {pname[:15]:<15}"
    header += " | å¹³å‡"
    print(header)
    print("-" * len(header))
    
    # æ‰“å°æ¯ä¸ªç­–ç•¥çš„ç»“æœ
    best_strategy = None
    best_avg = -1
    
    for strategy_name, strategy_results in results.items():
        row = f"{strategy_name:<20}"
        total = 0
        count = 0
        for pname in problem_names:
            if pname in strategy_results:
                acc = strategy_results[pname]["accuracy"]
                row += f" | {acc:>14.1f}%"
                total += acc
                count += 1
            else:
                row += f" | {'N/A':>15}"
        
        avg = total / count if count > 0 else 0
        row += f" | {avg:>5.1f}%"
        print(row)
        
        if avg > best_avg:
            best_avg = avg
            best_strategy = strategy_name
    
    print("-" * len(header))
    print(f"\\nğŸ† æœ€ä½³ç­–ç•¥: {best_strategy} (å¹³å‡å‡†ç¡®ç‡: {best_avg:.1f}%)")
    
    return best_strategy


# =============================================================================
# ä½œä¸šæäº¤ç”¨çš„ç®€å•æµ‹è¯•å‡½æ•°
# =============================================================================

def test_your_prompt(system_prompt: str, test_name: str = "Standard") -> tuple[int, int]:
    """ä½œä¸šæäº¤ç”¨ï¼šè¿è¡ŒNUM_RUNS_TIMESæ¬¡æµ‹è¯•ï¼Œè¿”å›(æˆåŠŸæ¬¡æ•°, æ€»æ¬¡æ•°)"""
    success_count = 0
    print(f"\\n{'='*50}")
    print(f"Testing: {test_name}")
    print(f"{'='*50}\\n")
    
    for idx in range(NUM_RUNS_TIMES):
        print(f"Running test {idx + 1} of {NUM_RUNS_TIMES}")
        response = chat(
            model="mistral-nemo:12b",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": USER_PROMPT},
            ],
            options={"temperature": 0.3},
        )
        output_text = response.message.content
        final_answer = extract_final_answer(output_text)
        if final_answer.strip() == EXPECTED_OUTPUT.strip():
            print("SUCCESS")
            success_count += 1
        else:
            print(f"Expected output: {EXPECTED_OUTPUT}")
            print(f"Actual output: {final_answer}")
    
    pass_rate = (success_count / NUM_RUNS_TIMES) * 100
    print(f"\\n{'='*50}")
    print(f"Final Results: {success_count}/{NUM_RUNS_TIMES} tests passed ({pass_rate:.1f}%)")
    print(f"{'='*50}")
    
    return success_count, NUM_RUNS_TIMES


# =============================================================================
# ä¸»å…¥å£
# =============================================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--experiment":
        # å®Œæ•´å®éªŒæ¨¡å¼ï¼šå¯¹æ¯”æ‰€æœ‰ç­–ç•¥
        print("\\nğŸ”¬ è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ...\\n")
        all_problems = [MAIN_PROBLEM] + EXTRA_PROBLEMS
        results = run_experiment(STRATEGIES, all_problems, num_runs=NUM_RUNS_TIMES, verbose=False)
        best = print_summary(results)
        
        print(f"\\nğŸ’¡ å»ºè®®: å°† YOUR_SYSTEM_PROMPT è®¾ç½®ä¸º STRATEGY_{best[0]}_{best[2:]}")
        print("   ç„¶åè¿è¡Œ python chain_of_thought.py è¿›è¡Œæœ€ç»ˆéªŒè¯")
        
    elif len(sys.argv) > 1 and sys.argv[1] == "--verbose":
        # è¯¦ç»†æ¨¡å¼ï¼šæ˜¾ç¤ºå®Œæ•´è¾“å‡º
        print("\\nğŸ“ è¯¦ç»†æ¨¡å¼ï¼šæ˜¾ç¤ºå®Œæ•´æ¨ç†è¿‡ç¨‹...\\n")
        success, answer, output = run_single_test(YOUR_SYSTEM_PROMPT, MAIN_PROBLEM, verbose=True)
        
    else:
        # é»˜è®¤æ¨¡å¼ï¼šä½œä¸šæäº¤æµ‹è¯•
        results = test_your_prompt(YOUR_SYSTEM_PROMPT, "Chain of Thought Strategy")
        success_count, total_runs = results
        pass_rate = (success_count / total_runs) * 100
        
        print(f"\\n{'='*50}")
        print(f"Final Results: {success_count}/{total_runs} tests passed ({pass_rate:.1f}%)")
        print(f"{'='*50}\\n")
        
        if pass_rate == 100.0:
            print("âœ… PERFECT! All tests passed with CoT strategy.")
        elif pass_rate >= 80.0:
            print("âœ… EXCELLENT! High success rate achieved.")
        elif pass_rate >= 50.0:
            print("âš ï¸  MODERATE. Consider trying other strategies.")
            print("   Run: python chain_of_thought.py --experiment")
        else:
            print("âŒ LOW. Need to improve the strategy.")
            print("   Run: python chain_of_thought.py --experiment")
